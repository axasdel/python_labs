from normalize_function import normalize
from string import ascii_letters
import re # –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è "—à–∞–±–ª–æ–Ω–æ–≤"

text = normalize('emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ')
def check_str(text):
    if text.isalnum() == True:
        return True
    return False

def tokensize(text):
    clean_str = re.sub(rf'[^0-9{alphabet}]', ' ', text) #–∑–∞–º–µ–Ω–∞ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ –º–µ—Ç–æ–¥ —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö —Å—Ç—Ä–æ–∫ re.sub: –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –ø–æ–¥ \
                                                        #"—à–∞–±–ª–æ–Ω" —Å–∏–º–≤–æ–ª—ã –∑–∞–º–µ–Ω—è—é—Ç—Å—è –ø—Ä–æ–±–µ–ª–æ–º, –∞ –Ω–µ–ø–æ–¥—Ö–æ–¥—è—â–∏–µ –æ—Å—Ç–∞—é—Ç—Å—è –≤ —Å—Ç—Ä–æ–∫–µ
    new_text = clean_str.split() #—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ –ø—Ä–æ–±–µ–ª–∞–º "—á–∏—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–∏"
    return new_text
print(tokensize(text))