# –õ–ê–ë–û–†–ê–¢–û–†–ù–´–ï –†–ê–ë–û–¢–´



## –õ–ê–ë–û–†–ê–¢–û–†–ù–ê–Ø –†–ê–ë–û–¢–ê 1

*–ó–∞–¥–∞–Ω–∏–µ 1. –ë–ª–æ–∫ –ê*
```python
name  = input('–ò–º—è:')
age = int(input('–í–æ–∑—Ä–∞—Å—Ç:'))
new_age = age + 1
print(f'–ü—Ä–∏–≤–µ—Ç, {name}! –ß–µ—Ä–µ–∑ –≥–æ–¥ —Ç–µ–±–µ –±—É–¥–µ—Ç {new_age}')
```
![img01](https://github.com/axasdel/python_labs/blob/main/src/images/lab01/img01.png)

*–ó–∞–¥–∞–Ω–∏–µ 2. –ë–ª–æ–∫ –ê*
```python
a = float(input("a:").replace(',', '.'))
b = float(input("b:").replace(',', '.'))
summa = a + b
avg = str((summa / 2))
if int(avg[3]) >= 5: avg = str(float(avg) + 0.01)
print(f'sum={summa}, avg ={avg[:4]}')
```
![img02](https://github.com/axasdel/python_labs/blob/main/src/images/lab01/img02.png)

*–ó–∞–¥–∞–Ω–∏–µ 3. –ë–ª–æ–∫ –ê*
```python
price = float(input('price:'))
discount = float(input('discount:'))
vat = float(input('vat:'))
base = price * (1 - discount/100)
vat_amount = base * (vat/100)
total = base + vat_amount
print(f'–ë–∞–∑–∞ –ø–æ—Å–ª–µ —Å–∫–∏–¥–∫–∏:{base}')
print(f'–ù–î–°:{vat_amount}')
print(f'–ò—Ç–æ–≥–æ –∫ –æ–ø–ª–∞—Ç–µ:{total}')
```
![img03](https://github.com/axasdel/python_labs/blob/main/src/images/lab01/img03.png)

*–ó–∞–¥–∞–Ω–∏–µ 4. –ë–ª–æ–∫ –ê*
```python
min = int(input('–ú–∏–Ω—É—Ç—ã:'))
hours = min // 60
minut = min % 60
print(f'{hours}:{minut}')
```
![img04](https://github.com/axasdel/python_labs/blob/main/src/images/lab01/img04.png)

*–ó–∞–¥–∞–Ω–∏–µ 5. –ë–ª–æ–∫ –ê*
```python
bio = input('–§–ò–û:')
fio = bio.split()
initials = ''.join([i[0] for i in fio]).upper()
dlina = 0
for l in fio:
    dlina += len(l)
print(f'–ò–Ω–∏—Ü–∏–∞–ª—ã:{initials}.')
print(f'–î–ª–∏–Ω–∞ (—Å–∏–º–≤–æ–ª–æ–≤):{dlina + 2}')
```
![img05](https://github.com/axasdel/python_labs/blob/main/src/images/lab01/img05.png)



## –õ–ê–ë–û–†–ê–¢–û–†–ù–ê–Ø –†–ê–ë–û–¢–ê 2

*–ó–∞–¥–∞–Ω–∏–µ 1. –ë–ª–æ–∫ –ê*
```python
nums = [1, 3, 2, 3]
def min_max(nums):
    nums_tup = []
    if len(nums) > 0:
        mini = nums_tup.append(min(nums))
        maxi = nums_tup.append(max(nums))
        print(tuple(nums_tup))
    else:
        raise ValueError
min_max(nums)
```
![img01](https://github.com/axasdel/python_labs/blob/main/src/images/lab02/img01.png)
![img11](https://github.com/axasdel/python_labs/blob/main/src/images/lab02/img11.png)
![img12](https://github.com/axasdel/python_labs/blob/main/src/images/lab02/img12.png)

*–ó–∞–¥–∞–Ω–∏–µ 2. –ë–ª–æ–∫ –ê*
```python
nums = []
def unique_sorted(nums):
    new_nums = sorted(set(nums))
    print(new_nums)
unique_sorted(nums)
```
![img02](https://github.com/axasdel/python_labs/blob/main/src/images/lab02/img02.png)
![img21](https://github.com/axasdel/python_labs/blob/main/src/images/lab02/img21.png)
![img22](https://github.com/axasdel/python_labs/blob/main/src/images/lab02/img22.png)

*–ó–∞–¥–∞–Ω–∏–µ 3. –ë–ª–æ–∫ –ê*
```python
mat = [[1, 2], [3, 4]]
def flatten(mat):
    new_mat = []
    for num in mat:
        if type(num) == tuple or type(num) == list:
            for i in range(len(num)):
                if num[i] != '':
                    new_mat.append(num[i])
        else:
            raise ValueError
    print(new_mat)
flatten(mat)
```
![img03](https://github.com/axasdel/python_labs/blob/main/src/images/lab02/img03.png)
![img31](https://github.com/axasdel/python_labs/blob/main/src/images/lab02/img31.png)
![img32](https://github.com/axasdel/python_labs/blob/main/src/images/lab02/img32.png)

*–ó–∞–¥–∞–Ω–∏–µ 1. –ë–ª–æ–∫ –ë*
```python
mat= [[1, 2], [3, 4]]

def check_rvanost(mat):
    dlina = len(mat[-1])
    for x in mat:
        if len(x) != dlina:
            raise ValueError
        else:
            return True
def transpose(mat):
    if check_rvanost:
        new_mat = []
        for stolbec in range(len(mat[-1])):
            new_row = []
            for row in range(len(mat)):
                new_row.append(mat[row][stolbec])
            new_mat.append(new_row)
    print(new_mat)
transpose(mat)
```
![matrix1](https://github.com/axasdel/python_labs/blob/main/src/images/lab02/matrix1.png)

*–ó–∞–¥–∞–Ω–∏–µ 2. –ë–ª–æ–∫ –ë*
```python
mat = [[1, 2], [3]]
def check_rvanost(mat):
    for i in range(len(mat)):
        if len(mat[i]) == len(mat[i+1]):
            return True
        else:
            return False
def row_sums(mat):
    new_mat = []
    for x in mat:
        if type(x) == list and check_rvanost(mat):
            summa = 0
            for i in range(len(x)):
                summa += x[i]
            new_mat.append(summa)
        else:
            raise ValueError
    print(new_mat)
row_sums(mat)
```
![matrix2](https://github.com/axasdel/python_labs/blob/main/src/images/lab02/matrix2.png)

*–ó–∞–¥–∞–Ω–∏–µ 3. –ë–ª–æ–∫ –ë*
```pyhon
```
![matrix3](https://github.com/axasdel/python_labs/blob/main/src/images/lab02/matrix3.png)

*–ó–∞–¥–∞–Ω–∏–µ 1. –ë–ª–æ–∫ –°*
```python
mat = [[1, 2], [3]]
def check_rvanost(mat):
    for i in range(len(mat)):
        if len(mat[i]) == len(mat[i+1]):
            return True
        else:
            return False
def row_sums(mat):
    new_mat = []
    for x in mat:
        if type(x) == list and check_rvanost(mat):
            summa = 0
            for i in range(len(x)):
                summa += x[i]
            new_mat.append(summa)
        else:
            raise ValueError
    print(new_mat)
row_sums(mat)
```
![tuples](https://github.com/axasdel/python_labs/blob/main/src/images/lab02/tuples.png)



## –õ–ê–ë–û–†–ê–¢–û–†–ù–ê–Ø –†–ê–ë–û–¢–ê 3

*–ó–∞–¥–∞–Ω–∏–µ 1. –ë–ª–æ–∫ –ê*
```python
def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    if casefold:
        text = text.casefold()
    if yo2e:
        text = text.replace('—ë', '–µ').replace('–Å', '–ï')
    symbols = ['t', 'r', 'n']
    for symb in symbols:
        comb = "\\" + symb
        text = re.sub(rf'{comb}', ' ', text) #–∑–∞–º–µ–Ω—è–µ–º –Ω–µ–ø–æ–¥—Ö–æ–¥—è—â—É—é –∫–æ–º–±–∏–Ω–∞—Ü–∏—é —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ –ø—Ä–æ–±–µ–ª
    for s in range(len(text)):
        try: 
            if text[s] + text[s+1] == '  ':
                text = text.replace('  ', ' ')
        except IndexError: #–ø—Ä–∏ –≤—ã—Ö–æ–¥–µ –∑–∞ –≥—Ä–∞–Ω–∏—Ü—ã
            break
    text = text.strip() #"—Å—Ö–ª–æ–ø—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç"
    return text
```
![normalize1](https://github.com/axasdel/python_labs/blob/main/src/images/lab03/norm1.png)
![normalize2](https://github.com/axasdel/python_labs/blob/main/src/images/lab03/norm2.png)
![normalize3](https://github.com/axasdel/python_labs/blob/main/src/images/lab03/norm3.png)
![normalize4](https://github.com/axasdel/python_labs/blob/main/src/images/lab03/norm4.png)


*–ó–∞–¥–∞–Ω–∏–µ 2. –ë–ª–æ–∫ –ê.*
```python
import re # –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è "—à–∞–±–ª–æ–Ω–æ–≤"

def tokenize(text):
    clear_text = re.sub(r'[^\w\s-]', ' ', text) #–∑–∞–º–µ–Ω—è–µ–º –≤—Å–µ –Ω–µ—É–≥–æ–¥–Ω–æ–µ –Ω–∞ –ø—Ä–æ–±–µ–ª—ã –≤ text
    new_text = clear_text.split() #—Ä–∞–∑–¥–µ–ª—è–µ–º –ø–æ –ø—Ä–æ–±–µ–ª—É
    return new_text #–≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫
```
![tokenize1](https://github.com/axasdel/python_labs/blob/main/src/images/lab03/tok1.png)
![tokenize2](https://github.com/axasdel/python_labs/blob/main/src/images/lab03/tok1.png)
![tokenize3](https://github.com/axasdel/python_labs/blob/main/src/images/lab03/tok3.png)
![tokenize4](https://github.com/axasdel/python_labs/blob/main/src/images/lab03/tok4.png)
![tokenize5](https://github.com/axasdel/python_labs/blob/main/src/images/lab03/tok5.png)

*–ó–∞–¥–∞–Ω–∏–µ 3. –ë–ª–æ–∫ –ê*
```python
from collections import Counter 

def count_freq(tokens: list):
    dict_token = Counter(tokens) #–∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–ª–∞—Å—Å counter, –ø–æ–¥—Å—á–∏—Ç—ã–≤–∞—é—â–∏–π —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –∫–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç –≤—Ö–æ–¥–∏—Ç –≤ –º–∞—Å—Å–∏–≤
    return dict_token

def top_n(slovar, n):
    spisok = []
    for key, value in slovar.items():
        spisok.append((key, value)) #–¥–µ–ª–∞–µ–º —Å–ø–∏—Å–æ–∫ –∏–∑ –∫–æ—Ä—Ç–µ–∂–µ–π, –≤ –∫–æ—Ç. –ø–æ–º–µ—â–µ–Ω—ã –∫–ª—é—á –∏ –∑–Ω–∞—á–µ–Ω–∏–µ 
    for i in range(len(spisok)):
        for j in range(i + 1, len(spisok)):
            if spisok[i][0] > spisok[j][0]: #—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–ª—é—á–µ–π –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É
                spisok[i], spisok[j] = spisok[j], spisok[i] 
    for i in range(len(spisok)):
        for j in range(i + 1, len(spisok)):
            if spisok[i][1] < spisok[j][1]: #—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —á–∞—Å—Ç–æ—Ç—ã
                spisok[i], spisok[j] = spisok[j], spisok[i]
    return spisok[:n] #–æ–±—Ä–µ–∑–∞–µ–º —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π
```
![count_freq_top_n1](https://github.com/axasdel/python_labs/blob/main/src/images/lab03/count_freq_top_n1.png)
![count_freq_top_n2](https://github.com/axasdel/python_labs/blob/main/src/images/lab03/count_freq_top_n2.png)

*–ë–ª–æ–∫ –í*
```python
import sys
sys.path.append(r'C:\Users\user\Desktop\python_labs\src')
from lib.normalize_function import normalize
from lib.tokenize_function import tokenize
from lib.count_freq_top_n_function import count_freq, top_n

import io
sys.stdin = io.TextIOWrapper(sys.stdin.buffer, encoding='utf-8')
text = sys.stdin.read().strip()
print(text)

norm_f = normalize(text)
tokens = tokenize(norm_f)
slovar = count_freq(tokens) #—Ç–∏–ø - —Å–ª–æ–≤–∞—Ä—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –≤ —Ñ-—Ü–∏–∏ top_n
slovar = count_freq(tokens) 
top = top_n(slovar, 5)

print("–í—Å–µ–≥–æ —Å–ª–æ–≤:",len(tokens))
print("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤:",len(slovar))
print("–¢–æ–ø-5:")
print(top)
for slova in top:
    print(slova[0], ':', slova[1])
```
![text_stats](https://github.com/axasdel/python_labs/blob/main/src/images/lab03/text_statss.png)



## –õ–ê–ë–û–†–ê–¢–û–†–ù–ê–Ø –†–ê–ë–û–¢–ê 4

*–ó–∞–¥–∞–Ω–∏–µ 1-2. –ë–ª–æ–∫ –ê*
```python
from pathlib import Path
import csv

def read_text(path, encoding ='utf-8'):
    path = Path(path) #–∫–ª–∞—Å—Å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–µ —Ç–æ–ª—å–∫–æ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É, –Ω–æ –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã —Å –Ω–∏–º
    with open(path, 'r', encoding=encoding) as f:
        return f.read()

try:
    text = read_text('src/data/lab04/input.txt', encoding='utf-8')
    print(text)
except FileNotFoundError:
    print('–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω')
except UnicodeDecodeError:
    print('–ù–µ–ø–æ–¥—Ö–æ–¥—è—â–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞')


def write_csv(rows, path, header):
    path = Path(path)
    if rows:
        last_dlina = len(rows[-1])
        for row in rows:
            if len(row) != last_dlina:
                raise ValueError
    with open(path, 'w', newline = '', encoding = 'utf-8') as f:
        csv_maker = csv.writer(f, delimiter=',')
        if header:
            csv_maker.writerow(header)
        for row in rows:
            csv_maker.writerow(row)

write_csv([("word","count"),("test",3)], "src/data/check.csv", None)  # —Å–æ–∑–¥–∞—Å—Ç CSV
```
![io](https://github.com/axasdel/python_labs/blob/main/src/images/lab04/io_txt_csv.png)

*–ë–ª–æ–∫ –í*
```python
from pathlib import Path
import csv

import sys
sys.path.append(r'C:\Users\user\Desktop\python_labs\src')
from lib.normalize_function import normalize
from lib.tokenize_function import tokenize
from lib.count_freq_top_n_function import count_freq, top_n


def read_text(path, encoding = 'utf-8'):
    path = Path(path)
    with open(path, 'r', encoding = 'utf-8') as f:
        return f.read()

def report_writer(path, count_f, encoding = 'utf-8'):
    path = Path(path)
    sortirovka = top_n(count_f, len(count_f))
    with open(path, 'w', newline = '', encoding='utf-8') as f:
        csv_maker = csv.writer(f, delimiter=',')
        csv_maker.writerow(('word', 'count'))
        for word, freq in sortirovka:
            csv_maker.writerow((word, freq))

try:
    text_i = read_text('src/data/lab04/input.txt', encoding='utf-8')
    norm = normalize(text_i)
    token = tokenize(norm)
    count_f = count_freq(token) 
    top = top_n(count_f, 5)

    report_writer('src/data/lab04/report.csv',count_f, encoding = 'utf-8')
    print('–í—Å–µ–≥–æ —Å–ª–æ–≤:', len(token))
    print('–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤:', len(count_f))
    for t in top:
        print(t[0], ':', t[1])
except FileNotFoundError:
    print('–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω')
except UnicodeDecodeError:
    print('–ù–µ–ø–æ–¥—Ö–æ–¥—è—â–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞')
```
![report](https://github.com/axasdel/python_labs/blob/main/src/images/lab04/text_report.png)



## –õ–ê–ë–û–†–ê–¢–û–†–ù–ê–Ø –†–ê–ë–û—Ç–ê 5

*–ó–∞–¥–∞–Ω–∏–µ 1. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è JSON <-> CSV*
```python
import sys

sys.path.append(r"C:\Users\user\Desktop\python_labs\src")
import json
import csv

from pathlib import Path


def json_to_csv(json_path, csv_path):
    json_newpath = Path(json_path)
    csv_newpath = Path(csv_path)

    if not json_newpath.exists():
        raise FileNotFoundError("–§–∞–π–ª –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")

    with json_newpath.open("r", encoding="utf-8") as jf:
        json_text = json.load(jf)

    if json_text is None:
        raise ValueError("–§–∞–π–ª –ø—É—Å—Ç")
    if len(json_text) == 0:
        raise ValueError("–§–∞–π–ª –ø—É—Å—Ç")
    if type(json_text) != list:
        raise ValueError("JSON –Ω–µ —Å–ø–∏—Å–æ–∫")
    if not all(isinstance(element, dict) for element in json_text):  # –≤—Å–µ –ª–∏ —ç–ª–µ–º–µ–Ω—Ç—ã - —Å–ª–æ–≤–∞—Ä–∏
        raise ValueError("JSON - —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π")

    fieldnames = list(json_text[0].keys())  # –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫–ª—é—á–µ–π 1–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è –≤ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –±—É–¥—É—é—â–µ–≥–æ csv
    with csv_newpath.open("w", encoding="utf-8", newline="") as cf:
        csv_writer = csv.DictWriter(cf, fieldnames=fieldnames, extrasaction="ignore")
        csv_writer.writeheader()  # –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–∏—à–Ω–∏—Ö –∫–ª—é—á–µ–π
        csv_writer.writerows(json_text)


def csv_to_json(csv_path, json_path):
    csv_newpath = Path(csv_path)
    json_newpath = Path(json_path)

    if not csv_newpath.exists():
        raise FileNotFoundError("–§–∞–π–ª –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")

    with csv_newpath.open("r", encoding="utf-8", newline="") as cf:
        csv_text = csv.DictReader(cf, delimiter=",")

        if not csv_text.fieldnames:
            raise ValueError("–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏")

        text = [dict(row) for row in csv_text]
        if len(text) == 0:
            raise ValueError("–§–∞–π–ª –ø—É—Å—Ç")

    with json_newpath.open("w", encoding="utf-8") as jf:
        json.dump(text, jf, ensure_ascii=False, indent=2)
        # –æ—Ç—Å—Ç—É–ø—ã


json_path = "src/lab05/data/samples/people.json"
csv_outpath = "src/lab05/data/result/people_from_json.csv"
csv_path = "src/lab05/data/samples/people.csv"
json_outpath = "src/lab05/data/result/people_from_csv.json"

json_to_csv(json_path, csv_outpath)
csv_to_json(csv_path, json_outpath)
```
![json_csv](https://github.com/axasdel/python_labs/blob/main/src/images/lab05/json_csv.png)
![csv_json](https://github.com/axasdel/python_labs/blob/main/src/images/lab05/csv_json.png)

*–ó–∞–¥–∞–Ω–∏–µ 2. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è CSV -> XLSX*
```python
import csv
from openpyxl import Workbook
from openpyxl.utils import get_column_letter

from pathlib import Path
import sys

sys.path.append(r"C:\Users\user\Desktop\python_labs\src")


def csv_to_xlsx(csv_path_1, xlsx_path_2):
    csv_newpath = Path(csv_path_1)
    xlsx_newpath = Path(xlsx_path_2)

    if not csv_newpath.exists():
        raise FileNotFoundError("–§–∞–π–ª–∞ csv –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")

    workbook = Workbook()  # —Å–æ–∑–¥–∞–Ω–∏–µ –∫–Ω–∏–≥–∏ —ç–∫—Å–µ–ª—å
    work_sheet = workbook.active  # –∞–∫—Ç–∏–≤–Ω—ã–π –ª–∏—Å—Ç
    work_sheet.title = "Sheet1"

    column_width = {}  # –¥–ª—è –º–∞–∫—Å —à–∏—Ä–∏–Ω—ã —Å—Ç–æ–ª–±—Ü–∞

    with csv_newpath.open("r", encoding="utf-8") as cf:
        csv_reading = csv.reader(cf)
        for row in csv_reading:
            work_sheet.append(row)
            for column_ind, value in enumerate(
                row, start=1
            ):  # enumerate –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è (–∏–Ω–¥–µ–∫—Å, –∑–Ω–∞—á–µ–Ω–∏–µ)
                cell_length = len(value)  # –¥–ª–∏–Ω–∞ –∑–Ω–∞—á–µ–Ω–∏—è
                if cell_length > column_width.get(
                    column_ind, 0
                ):  # —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –¥–ª–∏–Ω–∞ –∑–Ω–∞—á–µ–Ω–∏—è > —Ç–µ–∫—É—â–µ–π –º–∞–∫—Å —à–∏—Ä–∏–Ω—ã
                    column_width[column_ind] = cell_length

    for column_ind, width in column_width.items():  # –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞, —à–∏—Ä–∏–Ω—ã –≤ —Å–ª–æ–≤–∞—Ä–µ
        letter = get_column_letter(
            column_ind
        )  # –∏—Å—Ö–æ–¥—è –∏–∑ –∏–Ω–¥–µ–∫—Å–∞, –ø—Ä–∏—Å–≤–∞–µ–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü–∞–º —ç–∫—Å–µ–ª–µ–≤—Å–∫–∏–µ –±—É–∫–≤—ã
        work_sheet.column_dimensions[letter].width = (
            (width + 2) if (width + 2) >= 8 else 8
        )  # –ø–æ 1 –æ—Ç—Å—Ç—É–ø—É —Å –æ–±–µ–∏—Ö —Å—Ç–æ—Ä–æ–Ω

    workbook.save(xlsx_newpath)


if __name__ == "__main__":  # –∑–∞–ø—É—Å–∫ –Ω–∞–ø—Ä—è–º—É—é
    csv_path = "src/lab05/data/samples/people.csv"
    xlsx_path = "src/lab05/data/result/res_people.xlsx"
    csv_to_xlsx(csv_path, xlsx_path)
```
![csv_xlsx](https://github.com/axasdel/python_labs/blob/main/src/images/lab05/csv_xlsx.png)



## –õ–ê–ë–û–†–ê–¢–û–†–ù–ê–Ø –†–ê–ë–û–¢–ê 6

*–ó–∞–¥–∞–Ω–∏–µ 1. CLI_TEXT*
```python
import argparse
from collections import Counter
from pathlib import Path

import sys
sys.path.append(r"C:\Users\user\Desktop\python_labs\src")
from lib.normalize_function import normalize
from lib.tokenize_function import tokenize
from lib.count_freq_top_n_function import count_freq, top_n


def cat_read_text(path, numeration = 0):
    new_path = Path(path)
    if not new_path.exists():
        raise FileNotFoundError('–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω')

    with open(new_path, 'r', encoding='utf-8') as f:
        if numeration:
            for num, row in enumerate(f, 1):
                print(f'{num}: {row}')
        else:
            print(f.read())



def main(): #–æ—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
    parser = argparse.ArgumentParser(description='CLI –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ–∫—Å—Ç–æ–º') #—Å–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞, –¥–ª—è –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏—è –µ–º—É –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ 
    subparsers = parser.add_subparsers(dest='command') #"–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä" –¥–ª—è –ø–æ–¥–∫–æ–º–∞–Ω–¥


    #–ø–æ–¥–∫–æ–º–∞–Ω–¥–∞ cat
    cat_parser = subparsers.add_parser('cat', help = '–í—ã–≤–µ—Å—Ç–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞')
    cat_parser.add_argument('--input', required=True)
    cat_parser.add_argument('-n', action='store_true', help = '–ù—É–º–µ—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫–∏')

    #–ø–æ–¥–∫–æ–º–∞–Ω–¥–∞ stats
    stats_parser = subparsers.add_parser('stats', help = '–ß–∞—Å—Ç–æ—Ç–∞ —Å–ª–æ–≤')
    stats_parser.add_argument('--input', required=True)
    stats_parser.add_argument('--top', type=int, default=5) #–µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ —É–∫–∞–∂–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ, —Ç–æ –æ–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–æ–º –±—É–¥–µ—Ç 5


    args = parser.parse_args()


    if args.command == 'cat': #–µ—Å–ª–∏ –ø–æ–¥–∫–æ–º–∞–Ω–¥–∞ cat
        try:
            cat_read_text(args.input, args.n)
        except Exception as e:
            parser.error('–û—à–∏–±–∫–∞ –≤ –ø–æ–¥–∫–æ–º–∞–Ω–¥–µ cat')

    if args.command == 'stats': #–µ—Å–ª–∏ –ø–æ–¥–∫–æ–º–∞–Ω–¥–∞ stats
        try:
            with open(args.input, 'r', encoding='utf-8') as f:
                text = f.read()

                norm_f = normalize(text)
                tokens = tokenize(norm_f)
                slovar = count_freq(tokens)  # —Ç–∏–ø - —Å–ª–æ–≤–∞—Ä—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –≤ —Ñ-—Ü–∏–∏ top_n
                top = top_n(slovar, args.top)

                print("–í—Å–µ–≥–æ —Å–ª–æ–≤:", len(tokens))
                print("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤:", len(slovar))
                print(f"–¢–æ–ø-5: {args.top}")
                for slova in top:
                    print(slova[0], ":", slova[1])
        except Exception as e:
            parser.error('–û—à–∏–±–∫–∞ –≤ –ø–æ–¥–∫–æ–º–∞–Ω–¥–µ stats')


if __name__ == '__main__':
    main()
```
![cat](https://github.com/axasdel/python_labs/blob/main/src/images/lab06/cat_test.png)
![stats](https://github.com/axasdel/python_labs/blob/main/src/images/lab06/stats_test.png)

*–ó–∞–¥–∞–Ω–∏–µ 2. CLI_CONVERT*
```python
import argparse
import json
import csv
from openpyxl import Workbook
from openpyxl.utils import get_column_letter
from pathlib import Path

import sys
sys.path.append(r"C:\Users\user\Desktop\python_labs\src")


def csv2xlsx(csv_path_1, xlsx_path_2):
    csv_newpath = Path(csv_path_1)
    xlsx_newpath = Path(xlsx_path_2)

    if not csv_newpath.exists():
        raise FileNotFoundError("–§–∞–π–ª–∞ csv –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")

    workbook = Workbook()  # —Å–æ–∑–¥–∞–Ω–∏–µ –∫–Ω–∏–≥–∏ —ç–∫—Å–µ–ª—å
    work_sheet = workbook.active  # –∞–∫—Ç–∏–≤–Ω—ã–π –ª–∏—Å—Ç
    work_sheet.title = "Sheet1"

    column_width = {}  # –¥–ª—è –º–∞–∫—Å —à–∏—Ä–∏–Ω—ã —Å—Ç–æ–ª–±—Ü–∞

    with csv_newpath.open("r", encoding="utf-8") as cf:
        csv_reading = csv.reader(cf)
        for row in csv_reading:
            work_sheet.append(row)
            for column_ind, value in enumerate(row, start=1):  # enumerate –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è (–∏–Ω–¥–µ–∫—Å, –∑–Ω–∞—á–µ–Ω–∏–µ)
                cell_length = len(value)  # –¥–ª–∏–Ω–∞ –∑–Ω–∞—á–µ–Ω–∏—è
                if cell_length > column_width.get(column_ind, 0):  # —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –¥–ª–∏–Ω–∞ –∑–Ω–∞—á–µ–Ω–∏—è > —Ç–µ–∫—É—â–µ–π –º–∞–∫—Å —à–∏—Ä–∏–Ω—ã
                    column_width[column_ind] = cell_length

    for column_ind, width in column_width.items():  # –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞, —à–∏—Ä–∏–Ω—ã –≤ —Å–ª–æ–≤–∞—Ä–µ
        letter = get_column_letter(column_ind)  # –∏—Å—Ö–æ–¥—è –∏–∑ –∏–Ω–¥–µ–∫—Å–∞, –ø—Ä–∏—Å–≤–∞–µ–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü–∞–º —ç–∫—Å–µ–ª–µ–≤—Å–∫–∏–µ –±—É–∫–≤—ã
        work_sheet.column_dimensions[letter].width = ((width + 2) if (width + 2) >= 8 else 8)  # –ø–æ 1 –æ—Ç—Å—Ç—É–ø—É —Å –æ–±–µ–∏—Ö —Å—Ç–æ—Ä–æ–Ω

    workbook.save(xlsx_newpath)


def json2csv(json_path, csv_path):
    json_newpath = Path(json_path)
    csv_newpath = Path(csv_path)

    if not json_newpath.exists():
        raise FileNotFoundError("–§–∞–π–ª –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")

    with json_newpath.open("r", encoding="utf-8") as jf:
        json_text = json.load(jf)

    if json_text is None:
        raise ValueError("–§–∞–π–ª –ø—É—Å—Ç")
    if len(json_text) == 0:
        raise ValueError("–§–∞–π–ª –ø—É—Å—Ç")
    if type(json_text) != list:
        raise ValueError("JSON –Ω–µ —Å–ø–∏—Å–æ–∫")
    if not all(isinstance(element, dict) for element in json_text):  # –≤—Å–µ –ª–∏ —ç–ª–µ–º–µ–Ω—Ç—ã - —Å–ª–æ–≤–∞—Ä–∏
        raise ValueError("JSON - —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π")

    fieldnames = list(json_text[0].keys())  # –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫–ª—é—á–µ–π 1–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è –≤ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –±—É–¥—É—é—â–µ–≥–æ csv
    with csv_newpath.open("w", encoding="utf-8", newline="") as cf:
        csv_writer = csv.DictWriter(cf, fieldnames=fieldnames, extrasaction="ignore")
        csv_writer.writeheader()  # –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–∏—à–Ω–∏—Ö –∫–ª—é—á–µ–π
        csv_writer.writerows(json_text)


def csv2json(csv_path, json_path):
    csv_newpath = Path(csv_path)
    json_newpath = Path(json_path)

    if not csv_newpath.exists():
        raise FileNotFoundError("–§–∞–π–ª –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")

    with csv_newpath.open("r", encoding="utf-8", newline="") as cf:
        csv_text = csv.DictReader(cf, delimiter=",")

        if not csv_text.fieldnames:
            raise ValueError("–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏")

        text = [dict(row) for row in csv_text]
        if len(text) == 0:
            raise ValueError("–§–∞–π–ª –ø—É—Å—Ç")

    with json_newpath.open("w", encoding="utf-8") as jf:
        json.dump(text, jf, ensure_ascii=False, indent=2)
        # –æ—Ç—Å—Ç—É–ø—ã


def main():
    parser = argparse.ArgumentParser(description='CLI –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞')
    subparsers = parser.add_subparsers(dest='command', help='–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã')


    #–ø–æ–¥–∫–æ–º–∞–Ω–¥–∞ json2csv
    json2csv_parser = subparsers.add_parser('json2csv', help='JSON -> CSV')
    json2csv_parser.add_argument('--in', required=True, dest='input_file', help='–í—Ö–æ–¥–Ω–æ–π JSON')
    json2csv_parser.add_argument('--out', required=True, dest='output_file', help='–í—ã—Ö–æ–¥–Ω–æ–π CSV')


    #–ø–æ–¥–∫–æ–º–∞–Ω–¥–∞ csv2json
    csv2json_parser = subparsers.add_parser('csv2json', help='CSV -> JSON')
    csv2json_parser.add_argument('--in', required=True, dest='input_file', help='–í—Ö–¥–Ω–æ–π CSV')
    csv2json_parser.add_argument('--out', required=True, dest='output_file', help='–í—ã—Ö–æ–¥–Ω–æ–π JSON')


    #–ø–æ–¥–∫–æ–º–∞–Ω–¥–∞ csv2xlsx
    csv2xlsx_parser = subparsers.add_parser('csv2xlsx', help='CSV -> XLSX')
    csv2xlsx_parser.add_argument('--in', required=True, dest='input_file', help='–í—Ö–æ–¥–Ω–æ–π CSV')
    csv2xlsx_parser.add_argument('--out', required=True, dest='output_file', help='–í—ã—Ö–æ–¥–Ω–æ–π XLSX')


    args = parser.parse_args()


    try:
        if args.command == 'json2csv':
            json2csv(args.input_file, args.output_file)
        elif args.command == 'csv2json':
            csv2json(args.input_file, args.output_file)
        elif args.command == 'csv2xlsx':
            csv2xlsx(args.input_file, args.output_file)
    except Exception as e:
        parser.error


if __name__ == '__main__':
    main()
```
![out_files](https://github.com/axasdel/python_labs/blob/main/src/images/lab06/out_files.png)



## –õ–ê–ë–û–†–ê–¢–û–†–ù–ê–Ø –†–ê–ë–û–¢–ê 7
```python
import pytest
from src.lib.text import normalize, tokenize, count_freq, top_n


@pytest.mark.parametrize(  # –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    "source, expected",
    [
        ("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t", "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"),
        ("—ë–∂–∏–∫, –Å–ª–∫–∞", "–µ–∂–∏–∫, –µ–ª–∫–∞"),
        ("Hello\r\nWorld", "hello world"),
        ("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ", "–¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã"),
        ("", ""),  # –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        ("  ", ""),  # –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–±–µ–ª–∞–º–∏
    ],
)
def test_normalize(source, expected):
    assert normalize(source) == expected  # –ø—Ä–æ–≤–µ—Ä–∫–∞


@pytest.mark.parametrize(
    "source, expected",
    [
        ("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä", ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]),
        ("hello,world!!!", ["hello", "world"]),
        ("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ", ["–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É", "–∫—Ä—É—Ç–æ"]),
        ("2025 –≥–æ–¥", ["2025", "–≥–æ–¥"]),
        ("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ", ["emoji", "–Ω–µ", "—Å–ª–æ–≤–æ"]),
        ("", []),  # –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        ("!@#$%^&*()", []),  # —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
        ("  ", []),  # –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ —Å –ø—Ä–æ–±–µ–ª–∞–º–∏
    ],
)
def test_tokenize(source, expected):
    assert tokenize(source) == expected


@pytest.mark.parametrize(
    "source, expected",
    [
        (["a", "b", "a", "c", "b", "a"], {"a": 3, "b": 2, "c": 1}),
        (["bb", "aa", "bb", "aa", "cc"], {"aa": 2, "bb": 2, "cc": 1}),
        ([], {}),  # –ø—É—Å—Ç—ã–µ —Å–ø–∏—Å–∫–∏
    ],
)
def test_count_freq(source, expected):
    assert count_freq(source) == expected


@pytest.mark.parametrize(
    "source, n, expected",
    [
        ({"a": 3, "b": 2, "c": 1}, 2, [("a", 3), ("b", 2)]),
        ({"aa": 2, "bb": 2, "cc": 1}, 2, [("aa", 2), ("bb", 2)]),
        ({}, 5, []),  # –ø—É—Å—Ç—ã–µ —Å–ª–æ–≤–∞—Ä–∏
    ],
)
def test_top_n(source, n, expected):
    assert top_n(source, n) == expected
```
1[res](https://github.com/axasdel/python_labs/blob/main/src/images/lab07/res_test_text.png)


```python
import pytest

import json
import csv
from src.lib.file_converting import json_to_csv, csv_to_json


@pytest.fixture  # —Å–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç-—Ñ–∞–π–ª –ø—Ä–∏ –ø–æ–º–æ—â–∏ —Ñ–∏–∫—Å—Ç—É—Ä—ã
def sample_json(tmp_path):
    json_newfile = tmp_path / "people.json"  # —Å–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç-—Ñ–∞–π–ª
    text = [
        {"name": "Alice", "age": 25, "city": "Moscow"},
        {"name": "Bob", "age": 30, "city": "Saint Petersburg"},
        {"name": "Marie", "age": 28, "city": "Novosibirsk"},
    ]
    with open(json_newfile, "w", encoding="utf-8") as jf:
        json.dump(text, jf, ensure_ascii=False)
    return json_newfile  # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É —Ç–µ—Å—Ç-—Ñ–∞–π–ª—É


@pytest.fixture
def sample_csv(tmp_path):
    csv_newfile = tmp_path / "people.csv"
    text = [
        ["name", "age", "city"],
        ["Alice", "25", "Moscow"],
        ["Bob", "30", "Saint Petersburg"],
        ["Marie", "28", "Novosibirsk"],
    ]
    with open(csv_newfile, "w", encoding="utf-8", newline="") as cf:
        csv_writer = csv.writer(cf)
        csv_writer.writerows(text)
    return csv_newfile


def test_json_to_csv(sample_json, tmp_path):
    csv_file = tmp_path / "people_from_jf.csv"

    json_to_csv(str(sample_json), str(csv_file))  # JSON -> CSV
    assert csv_file.exists()  # —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª

    with open(csv_file, "r", encoding="utf-8") as cf:
        csv_reader = csv.DictReader(cf)
        rows = list(csv_reader)

        assert len(rows) == 3  # –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        assert rows[0]["name"] == "Alice"
        assert rows[0]["age"] == "25"
        assert rows[0]["city"] == "Moscow"


def test_csv_to_json(sample_csv, tmp_path):
    json_file = tmp_path / "people_from_cf.json"

    csv_to_json(str(sample_csv), str(json_file))
    assert json_file.exists()

    with open(json_file, "r", encoding="utf-8") as jf:
        json_reader = json.load(jf)

        assert len(json_reader) == 3
        assert json_reader[0]["name"] == "Alice"
        assert json_reader[0]["age"] == "25"
        assert json_reader[0]["city"] == "Moscow"
```
![res2]((https://github.com/axasdel/python_labs/blob/main/src/images/lab07/res_test_json_csv.png)